"""
–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–æ–π —Ä–∞–±–æ—Ç—ã –ø–æ NLP
"""

import nltk
from nltk.corpus import gutenberg
import os

def download_nltk_resources():
    """–°–∫–∞—á–∏–≤–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Ä–µ—Å—É—Ä—Å—ã NLTK"""
    print("üì• –°–∫–∞—á–∏–≤–∞–µ–º —Ä–µ—Å—É—Ä—Å—ã NLTK...")
    
    # –û—Å–Ω–æ–≤–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã
    resources = [
        'punkt',           # –¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä
        'punkt_tab',       # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã –¥–ª—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞
        'stopwords',       # –°—Ç–æ–ø-—Å–ª–æ–≤–∞
        'wordnet',         # –õ–µ–º–º–∞—Ç–∏–∑–∞—Ç–æ—Ä
        'omw-1.4',         # Open Multilingual WordNet
        'gutenberg'        # –ö–æ—Ä–ø—É—Å —Ç–µ–∫—Å—Ç–æ–≤
    ]
    
    for resource in resources:
        try:
            nltk.download(resource, quiet=True)
            print(f"   ‚úÖ {resource}")
        except Exception as e:
            print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å {resource}: {e}")
    
    print("‚úÖ –í—Å–µ —Ä–µ—Å—É—Ä—Å—ã NLTK –∑–∞–≥—Ä—É–∂–µ–Ω—ã!")

def load_gutenberg_corpus(book_name='carroll-alice.txt'):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ—Ä–ø—É—Å –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ Gutenberg"""
    try:
        print(f"üìö –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–Ω–∏–≥—É: {book_name}")
        text = gutenberg.raw(book_name)
        print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ!")
        print(f"üìä –†–∞–∑–º–µ—Ä —Ç–µ–∫—Å—Ç–∞: {len(text):,} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"üìñ –ü–µ—Ä–≤—ã–µ 300 —Å–∏–º–≤–æ–ª–æ–≤:\n{text[:300]}...")
        return text
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ç–µ–∫—Å—Ç–∞: {e}")
        return None

def load_custom_corpus(file_path):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∫–æ—Ä–ø—É—Å –∏–∑ —Ñ–∞–π–ª–∞"""
    try:
        print(f"üìÅ –ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∞–π–ª: {file_path}")
        with open(file_path, 'r', encoding='utf-8') as file:
            text = file.read()
        print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ!")
        print(f"üìä –†–∞–∑–º–µ—Ä —Ç–µ–∫—Å—Ç–∞: {len(text):,} —Å–∏–º–≤–æ–ª–æ–≤")
        return text
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞: {e}")
        return None

def save_processed_data(tokens, filename='processed_tokens.txt'):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã"""
    os.makedirs('data/processed', exist_ok=True)
    filepath = os.path.join('data/processed', filename)
    
    with open(filepath, 'w', encoding='utf-8') as f:
        for token in tokens:
            f.write(token + '\n')
    
    print(f"üíæ –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {filepath}")
    print(f"üìù –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {len(tokens):,}")

def show_corpus_info():
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ—Ä–ø—É—Å–∞ –≤ Gutenberg"""
    try:
        file_ids = gutenberg.fileids()
        print("\nüìö –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–Ω–∏–≥–∏ –≤ Gutenberg:")
        for i, file_id in enumerate(file_ids[:10]):  # –ø–æ–∫–∞–∂–µ–º –ø–µ—Ä–≤—ã–µ 10
            print(f"   {i+1}. {file_id}")
        if len(file_ids) > 10:
            print(f"   ... –∏ –µ—â–µ {len(file_ids) - 10} –∫–Ω–∏–≥")
        return file_ids
    except Exception as e:
        print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –∫–Ω–∏–≥: {e}")
        return []